Reference: https://adp-gptlearning.udemy.com/course/azure-databricks-spark-core-for-data-engineers/learn/lecture/27514596#overview

# Section 17: Using SQL in Spark Applications

- In order to access a dataframe from SQL, Spark gives you two options.
  1. Create a Temporary view
  2. Create a Global view

## 17.1 Local Temp View

- Temp View is **_only valid within a Spark session_**, so it's not available in another notebook.
- Also, if you detach the notebook from the cluster and reattach it, this view is not available.

```python
# demo/4.sql_temp_view_demo

# MAGIC %run "../includes/configuration"

# Fetch the Dataframe (for which view needs to be created)
race_results_df = spark.read.parquet(f"{presentation_folder_path}/race_results")

# Step 1. Create temporary views on dataframes
race_results_df.createOrReplaceTempView("v_race_results")

# Step 2. Access the view from SQL Cell
%sql
SELECT * FROM v_race_results;

# Step 3. Access the view from Python Cell (and save it in Dataframe)
race_results_2019_df = spark.sql(f"SELECT * FROM v_race_results WHERE race_year = 2020")
display(race_results_2019_df)
```

## 17.2 Global Temp View

- Global Temp View is **_available within the entire application_**.
- **NOTE**: In the context of Databricks, an **_application is basically all the notebooks that are attached to the Databricks cluster_**. \
  So, any notebook we attach to this cluster here, will have access to the global temporary view.

```python
# demo/4.sql_temp_view_demo

# MAGIC %run "../includes/configuration"

# Fetch the Dataframe (for which view needs to be created)
race_results_df = spark.read.parquet(f"{presentation_folder_path}/race_results")

# Step 1. Create global temporary views on dataframes
race_results_df.createOrReplaceGlobalTempView("gv_race_results")

# Step 2. Access the view from SQL Cell
%sql
SHOW TABLES;
SHOW TABLES N global_temp;
SELECT * global_temp.gv_race_results;

# Step 3. Access the view from Python Cell (and save it in Dataframe)
race_results_2019_df2 = spark.sql("SELECT * FROM global_temp.gv_race_results")
race_results_2019_df2.show()
display(race_results_2019_df2)

# Step 4. Acesss the view from another notebook
```


# Section 18: Spark SQL - Databases/ Tables/ Views

## 18.1 SparkSQL Introduction - Hive Meta Store
- Our data is stored in our Data Lake as files of varying types such as CSV, JSON and Parquet.
- In order for Spark to treat this data as tables and columns, we need to register this data in a meta store.
- Meta Store is nothing but a storage for storing the metadata about the data files.
- For example, things like the location of the file, the format of the data, column names, etc.
- Spark uses a _meta store provided by the Apache Hive project_ for this, which is called **Hive Meta Store**. It is the most commonly used metadata in the Data Lake space.
- For choosing the storage for hive meta store, we have a choice.
  - We can either choose the _Default Databricks_ managed Meta Store
  - Or the External Storage option of your own - Azure SQL, MySQL, MariaDB and a few others.
- Once we've registered our tables in the Hive Meta Store, we can then use Spark SQL to access these tables like we would in a relational DB.

- Just to summarize, the **data is usually stored in an object storage which is ADLS**, in our case.\
  **Hive Meta Store keeps the information about the file, such as the location, name of the file, table, column, etc..**

- When you run a Spark SQL command, Spark uses the meta store to apply the schema and access the files accordingly, as if we are accessing any relational table.

|         |       |                    | Databricks Workspace |       |       |       |
|---------|-------|--------------------|----------------------|-------|-------|-------|
|         |       |                    |      Database        |       |       |       |
|         | Table |                    |                      |       | Views |       |
| Managed |       | External/Unmanaged |                      |   -   |       |   -   |

1. **Databricks Workspace** have Databases(Schemas).
2. **Database** have Tables and Views.
3. **Tables** are basically structures given to the data stored in an object storage(ADLS here). There are two types of tables in Spark.
    1. **Managed tables** : Here Spark maintains both the metadata in Hive Meta Store and also the data files associated with the table, which is stored in ADLS here.
       - Dropping it deletes the files AND drops the table.
    3. **External/Unmanaged tables** : Here Spark only manages the metadata and we manage the data files. i.e.We specify the location of the data files and Spark doesn't decide it for itself.
       - Dropping it does NOT delete the files.
4. **Views** can be built on the tables with a selection of data. You can apply a _FILTER_ to a table, or _SELECT CERTAIN COLUMNS_ and then create a view with that limited information.

**Reference**: 
- https://spark.apache.org/docs/latest/api/python/reference/index.html
- https://spark.apache.org/docs/latest/index.html
- https://spark.apache.org/docs/latest/sql-ref.html - SQL Syntax, DDL, DML statements

## 18.2 Databases
**Reference**:
- https://spark.apache.org/docs/latest/sql-ref-syntax-ddl-create-database.html
- https://spark.apache.org/docs/latest/sql-ref-syntax.html#ddl-statements (CHECK?)

```sql
# demo/6.sql_objects_demo

-- 1. Create Database
CREATE DATABASE demo;
CREATE DATABASE IF NOT EXISTS demo;

-- 2. Data tab in the UI
-- Databricks >> "Data" tab >> Verify demo DB in the "Databases" list, which has no tables.

-- 3. SHOW command
SHOW databases;

-- 4. DESCRIBE command
DESCRIBE DATABASE demo; 
DESCRIBE DATABASE EXTENDED demo; 

-- 5. Find the current database
SELECT CURRENT_DATABASE();

-- 6. Change the current database
SHOW TABLES;
SHOW TABLES IN demo;
USE demo;

SELECT CURRENT_DATABASE();
SHOW TABLES;
```


## 18.3 Managed Tables
```sql
# demo/6.sql_objects_demo

-- MAGIC %run "../includes/configuration"

-- Create a Dataframe and write that data into Table
-- MAGIC %python
-- MAGIC race_results_df = spark.read.parquet(f"{presentation_folder_path}/race_results")
-- MAGIC race_results_df.write.format("parquet").saveAsTable("demo.race_results_python")

SHOW TABLES IN demo;
DESC EXTENDED race_results_python;
SELECT * FROM demo.race_results_python WHERE race_year = 2020;

-- 1. Create managed table using Python

-- 2. Create managed table using SQL
-- 3. Effect of dropping a managed table
-- 4. Describe table 

```


## 18.4 External Tables



## 18.5 Views
```sql
# demo/6.sql_objects_demo

SELECT CURRENT_DATABASE();

-- 1. Create Temp View
CREATE OR REPLACE TEMP VIEW v_race_results
AS
SELECT *
  FROM demo.race_results_python
 WHERE race_year = 2018;

SELECT * FROM v_race_results;

-- 2. Create Global Temp View
CREATE OR REPLACE GLOBAL TEMP VIEW gv_race_results
AS
SELECT *
  FROM demo.race_results_python
 WHERE race_year = 2012;

SELECT * FROM global_temp.gv_race_results
SHOW TABLES IN global_temp;

-- 3. Create Permanent View (It will be registered on Hive MetaStore)
CREATE OR REPLACE VIEW demo.pv_race_results
AS
SELECT *
  FROM demo.race_results_python
 WHERE race_year = 2000;

SHOW TABLES IN demo;
SELECT * FROM demo.pv_race_results;
```

# Section 19: SparkSQL - Filters/Joins/Aggregations

## 19.1 SQL DML Basics, Simple/Aggregate/Window Functions

**Reference:**
- BUILT FUNCTIONS: https://spark.apache.org/docs/latest/api/sql/index.html
- FUNCTIONS: https://spark.apache.org/docs/latest/sql-ref-functions.html
- AGGREGATE FUNCTIONS: https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#aggregate-functions
- WINDOW FUNCTIONS: https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#window-functions

```sql
# demo/7.sql_basics_demo
# demo/8.sql_functions_demo

SHOW DATABASES;
SELECT CURRENT_DATABASE()
USE f1_processed;
SHOW TABLES;

-- DML BASICS
SELECT *, name, dob AS date_of_birth
  FROM drivers
  WHERE nationality = 'British' AND dob >= '1990-01-01';

DESC drivers;

SELECT name, nationality,dob 
  FROM drivers
  WHERE (nationality = 'British' AND dob >= '1990-01-01') OR nationality = 'Indian'
  ORDER BY nationality ASC, dob DESC;

-- SIMPLE FUNCTIONS
SELECT *,
    CONCAT(driver_ref, '-', code) AS new_driver_ref,
    SPLIT(name, ' ')[1] surname
  FROM drivers;

SELECT *,
    current_timestamp,
    date_format(dob, 'dd-MM-yyyy'),    -- Change date format
    date_add(dob, 1),                  -- Add Date by 1
  FROM drivers
  WHERE dob = '2000-05-11';

-- AGGREGATES
SELECT
    COUNT(*),
    MAX(dob)
  FROM drivers;

SELECT COUNT(*) 
  FROM drivers
  WHERE nationality = 'British' ;

SELECT nationality, COUNT(*) 
  FROM drivers
  GROUP BY nationality
  HAVING COUNT(*) > 100
  ORDER BY nationality;

-- WINDOW FUNCTIONS:
SELECT nationality, name, dob,
    RANK() OVER(PARTITION BY nationality ORDER BY dob DESC) AS age_rank
  FROM drivers
  ORDER BY nationality, age_rank;

```

## 19.2 SQL Joins

```sql
# demo/9.sql_joins_demo

USE f1_presentation;
DESC driver_standings;

-- Create View1 from driver_standings
CREATE OR REPLACE TEMP VIEW v_driver_standings_2018
  AS
  SELECT race_year, driver_name, team, total_points, wins, rank
    FROM driver_standings
    WHERE race_year = 2018;
SELECT * FROM v_driver_standings_2018

-- Create View2 from driver_standings
CREATE OR REPLACE TEMP VIEW v_driver_standings_2020
  AS
  SELECT race_year, driver_name, team, total_points, wins, rank
    FROM driver_standings
    WHERE race_year = 2020;
SELECT * FROM v_driver_standings_2020;

-- INNER JOIN
SELECT *
  FROM v_driver_standings_2018 d_2018
  JOIN v_driver_standings_2020 d_2020 ON (d_2018.driver_name = d_2020.driver_name)

-- LEFT JOIN
SELECT *
  FROM v_driver_standings_2018 d_2018
  LEFT JOIN v_driver_standings_2020 d_2020 ON (d_2018.driver_name = d_2020.driver_name)

-- RIGHT JOIN
SELECT *
  FROM v_driver_standings_2018 d_2018
  RIGHT JOIN v_driver_standings_2020 d_2020 ON (d_2018.driver_name = d_2020.driver_name)

-- FULL JOIN
SELECT *
  FROM v_driver_standings_2018 d_2018
  FULL JOIN v_driver_standings_2020 d_2020 ON (d_2018.driver_name = d_2020.driver_name)

-- SEMI JOIN (SELECT columns only from Left Table)
SELECT *
  FROM v_driver_standings_2018 d_2018
  SEMI JOIN v_driver_standings_2020 d_2020 ON (d_2018.driver_name = d_2020.driver_name)

-- ANTI JOIN (SELECT columns only from Left Table AND fetch all those records not Selected in Left Table)
SELECT *
  FROM v_driver_standings_2018 d_2018
  ANTI JOIN v_driver_standings_2020 d_2020 ON (d_2018.driver_name = d_2020.driver_name)

-- CROSS JOIN (Joins all records from Left Tables with Right Tables)
SELECT *
  FROM v_driver_standings_2018 d_2018
  CROSS JOIN v_driver_standings_2020 d_2020

```











